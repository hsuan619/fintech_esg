import streamlit as st
import tempfile
import os
import re
import pandas as pd
import json
import ast
from datetime import datetime
from markitdown import MarkItDown  # éœ€å®‰è£: pip install markitdown

# è¨­å®šé é¢é…ç½® (å¿…é ˆæ˜¯ç¬¬ä¸€å€‹ Streamlit æŒ‡ä»¤)
st.set_page_config(page_title="ESG æ¼‚ç¶ ç¨½æ ¸å°å¹«æ‰‹", layout="wide", page_icon="ğŸŒ±")

# ==========================================
# æ ¸å¿ƒé‚è¼¯å€ (ç§»æ¤è‡ª app_bk.py ä¸¦å¢å¼·)
# ==========================================

def clean_year(value):
    """å°‡è¼¸å…¥è½‰æ›ç‚ºå¹´ä»½æ•´æ•¸ (e.g. '2015' -> 2015)"""
    try:
        if pd.isna(value) or value == 'None' or value is None: 
            return None
        # è™•ç†å¯èƒ½çš„æµ®é»æ•¸å¹´ä»½æˆ–å­—ä¸²
        return int(float(str(value).split('.')[0]))
    except:
        return None

def clean_value(value):
    """
    é€šç”¨æ•¸å€¼æ¸…æ´— (ä¾†è‡ª app_bk.py å¢å¼·ç‰ˆ)ï¼š
    1. ç§»é™¤é€—è™Ÿ (,)
    2. ç§»é™¤å–®ä½ (tCO2e, tonsç­‰)
    3. åˆ¤æ–·æ˜¯å¦ç‚ºç™¾åˆ†æ¯”
    4. [æ–°å¢] åˆ¤æ–·æ‹¬è™Ÿæ•¸å€¼ç‚ºè² æ•¸ï¼Œä¾‹å¦‚ (5)% -> -0.05
    å›å‚³: (æ•¸å€¼ float, æ˜¯å¦ç‚ºç™¾åˆ†æ¯” bool, æ˜¯å¦ç‚ºæ‹¬è™Ÿè² æ•¸æ ¼å¼ bool)
    """
    try:
        if pd.isna(value) or value == 'None': return None, False, False
        str_val = str(value).strip()
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºè² æ•¸ (æ‹¬è™ŸåŒ…åœ)
        is_negative_format = '(' in str_val and ')' in str_val
        
        is_percentage = '%' in str_val
        
        # ç§»é™¤éæ•¸å­—å­—ç¬¦ (ä¿ç•™å°æ•¸é»)
        clean_str = re.sub(r'[^\d.]', '', str_val)
        
        if not clean_str: return None, False, False
        
        float_val = float(clean_str)
        
        # è™•ç†è² è™Ÿé‚è¼¯
        if is_negative_format or '-' in str_val:
            float_val = -abs(float_val)
        
        # å¦‚æœåŸå§‹å­—ä¸²æœ‰%ï¼Œé™¤ä»¥100
        if is_percentage:
            return float_val / 100, True, is_negative_format
        
        return float_val, False, is_negative_format
    except:
        return None, False, False

def calculate_risk(json_data):
    """
    æ ¸å¿ƒé¢¨éšªè¨ˆç®—å‡½å¼ (ç§»æ¤è‡ª app_bk.py)
    æ”¯æ´: ç·šæ€§é æœŸæ³•ã€è·é›¢ç›®æ¨™æ³•ã€çµ•å°å€¼å‹•æ…‹è½‰ç™¾åˆ†æ¯”
    å›å‚³: (DataFrame, è­¦å‘Šåˆ—è¡¨)
    """
    results = []
    warnings = []  # è¿½è¹¤éœ€è¦é¡¯ç¤ºè­¦å‘Šçš„è¨˜éŒ„

    # --- é è™•ç†ï¼šç‚ºæ¯ç­†è³‡æ–™åˆ¤æ–·æ˜¯å¦èˆ‡åŒçµ„çš„å‰ä¸€ç­† target ä¸åŒ ---
    from collections import defaultdict
    change_notes_by_index = {}
    entries = []
    for idx, it in enumerate(json_data):
        f = it.get('Standardized_Focus_Area', 'Unknown')
        m = it.get('Standardized_Metric', 'Unknown')
        s = it.get('Scope', 'Global')
        norm_s = it.get('Normalize_Scope') or it.get('Normalized_Scope') or it.get('NormalizedScope') or it.get('Standardized_Scope') or s
        ry = clean_year(it.get('Report_Year'))
        ty = clean_year(it.get('Target_Deadline'))
        tv = it.get('Target_Value')
        by = clean_year(it.get('Baseline_Year'))
        entries.append({'idx': idx, 'focus': f, 'metric': m, 'norm_scope': norm_s, 'report_year': ry, 'target_year': ty, 'target_val': tv, 'baseline_year': by})

    groups = defaultdict(list)
    for e in entries:
        groups[(e['focus'], e['metric'], e['norm_scope'])].append(e)

    for key, lst in groups.items():
        # å…ˆæŒ‰ Report_Year å‡åºæ’åˆ—ï¼Œç¼ºå¹´è€…æ”¾åˆ°æœ€å¾Œï¼ˆç¶­æŒåŸå§‹é †åºï¼‰
        lst_with_year = [e for e in lst if e['report_year'] is not None]
        lst_no_year = [e for e in lst if e['report_year'] is None]
        lst_sorted = sorted(lst_with_year, key=lambda x: x['report_year']) + lst_no_year
        for i in range(1, len(lst_sorted)):
            prev = lst_sorted[i-1]
            cur = lst_sorted[i]
            prev_ty = prev.get('target_year')
            prev_tv = prev.get('target_val')
            cur_ty = cur.get('target_year')
            cur_tv = cur.get('target_val')
            prev_by = prev.get('baseline_year')
            cur_by = cur.get('baseline_year')
            # å…ˆæ¯”è¼ƒ targetï¼ˆdeadline æˆ– valueï¼‰ï¼Œè‹¥ target ç›¸åŒå†æ¯”è¼ƒ baseline year
            if (prev_ty != cur_ty) or (prev_tv != cur_tv):
                change_notes_by_index[cur['idx']] = f"; ç›®æ¨™å·²è®Šæ›´ (å‰: {prev_ty}å¹´ {prev_tv} -> ç¾: {cur_ty}å¹´ {cur_tv})"
                if prev_by != cur_by:
                    change_notes_by_index[cur['idx']] += f"; åŸºæº–å¹´å·²è®Šæ›´ (å‰: {prev_by} -> ç¾: {cur_by})"
            elif (prev_ty != cur_ty) or (prev_tv != cur_tv):
                change_notes_by_index[cur['idx']] = f"ç›®æ¨™å·²è®Šæ›´ (å‰: {prev_ty}å¹´ {prev_tv} -> ç¾: {cur_ty}å¹´ {cur_tv})"
    
    for idx, item in enumerate(json_data):
        try:
            # --- A. åŸºç¤è³‡æ–™è®€å– ---
            focus_area = item.get('Standardized_Focus_Area', 'Unknown')
            metric = item.get('Standardized_Metric', 'Unknown')
            scope = item.get('Scope', 'Global')
            report_year = clean_year(item.get('Report_Year'))
            
            # è®€å–ç›®æ¨™ (Target)
            target_year = clean_year(item.get('Target_Deadline'))
            target_val_str = item.get('Target_Value')
            # å„ªå…ˆå˜—è©¦å¯èƒ½çš„æ¨™æº–åŒ– scope æ¬„ä½
            norm_scope = item.get('Normalize_Scope') or item.get('Normalized_Scope') or item.get('NormalizedScope') or item.get('Standardized_Scope') or scope
            # å¾é è™•ç†çµæœä¸­å–å¾—è®Šæ›´å‚™è¨»ï¼ˆè‹¥æœ‰ï¼‰
            change_note = change_notes_by_index.get(idx, "")
            
            # è®€å–åŸºæº–å¹´ (Baseline)
            base_year = clean_year(item.get('Baseline_Year'))
            
            # ç›®æ¨™é€šå¸¸æ˜¯ç™¾åˆ†æ¯”ï¼Œå¼·åˆ¶è¦–ç‚ºç™¾åˆ†æ¯”è™•ç†
            target_reduction, _, _ = clean_value(target_val_str)
            
            # å¦‚æœç›®æ¨™æ²’å¯«%ï¼Œä½†æ•¸å€¼æ¯”å¦‚æ˜¯ 20ï¼Œé€šå¸¸æŒ‡ 20% (0.2)
            if target_reduction is not None and target_reduction > 1: 
                target_reduction /= 100
            
            # --- B. è§£æé€²åº¦æ­·å² (Progress History) ---
            history_str = item.get('Progress_History', '[]')
            try:
                if isinstance(history_str, list):
                    history_list = history_str
                else:
                    history_list = ast.literal_eval(history_str)
            except:
                history_list = []
            
            if not history_list:
                results.append({
                    "Focus_Area": focus_area, "Metric": metric, "Report_Year": report_year,
                    "Risk_Level": "æ•¸æ“šä¸è¶³", "Analysis_Note": "ç„¡æ­·å²é€²åº¦æ•¸æ“š", "Target": f"{target_year}å¹´ {target_val_str}",
                    "Has_Negative_Warning": False,
                    "Target_Change_Note": change_note
                })
                continue
            
            # æ•´ç†æ­·å²æ•¸æ“š
            history_map = {}
            valid_history = []
            has_negative_warning = False  # è¿½è¹¤æ˜¯å¦æœ‰è² æ•¸è­¦å‘Š
            
            for h in history_list:
                y = clean_year(h.get('Year'))
                raw_v = h.get('Value')
                v, is_pct, is_negative_fmt = clean_value(raw_v)
                
                if y is not None and v is not None:
                    record = {'Year': y, 'Value': v, 'Is_Pct': is_pct, 'Raw': raw_v, 'Is_Negative_Fmt': is_negative_fmt}
                    valid_history.append(record)
                    history_map[y] = record
                    # å¦‚æœæœ€æ–°å¹´ä»½æœ‰è² æ•¸æ ¼å¼è­¦å‘Š
                    if is_negative_fmt:
                        has_negative_warning = True
            
            if not valid_history:
                results.append({
                    "Focus_Area": focus_area, "Metric": metric, "Report_Year": report_year, "Scope": scope,
                    "Risk_Level": "æ•¸æ“šä¸è¶³", "Note": "ç„¡æ­·å²é€²åº¦æ•¸æ“š", "Target": f"{target_year}å¹´ {target_val_str}",
                    "Current_Status": "N/A",
                    "Has_Negative_Warning": False, "Target_Change_Note": change_note, "Analysis_Note": ""
                })
                continue
            
            valid_history.sort(key=lambda x: x['Year'])
            latest_record = valid_history[-1]
            Y_current = latest_record['Year']
            
            # å¦‚æœç¼ºå°‘åŸºæº–å¹´ï¼Œä½†æœ‰æ­·å²æ•¸æ“šï¼Œé¡¯ç¤ºè©²å¹´åº¦çš„æ¸›é‡ç‹€æ³
            if base_year is None:
                actual_reduction = latest_record['Value']
                results.append({
                    "Focus_Area": focus_area, "Metric": metric, "Report_Year": report_year, "Scope": scope,
                    "Risk_Level": "æ•¸æ“šä¸è¶³",  "Target": f"{target_year}å¹´ {target_val_str}",
                    "Current_Status": f"{Y_current}å¹´ (æ¸›é‡ {actual_reduction:.1%})" if actual_reduction is not None else "N/A",
                    "Has_Negative_Warning": False, "Target_Change_Note": change_note, "Analysis_Note": "ç„¡æ³•è¨ˆç®—é¢¨éšªï¼ˆç¼ºå°‘åŸºæº–å¹´ï¼‰"
                })
                continue
            
            # --- C. è¨ˆç®—å¯¦éš›æ¸›é‡ (Actual Reduction) ---
            actual_reduction = 0.0
            calc_method = ""
            
            # åˆ¤æ–·æ˜¯ç”¨ã€Œçµ•å°å€¼ã€ç®—é‚„æ˜¯ç›´æ¥æ‹¿ã€Œç™¾åˆ†æ¯”ã€
            if not latest_record['Is_Pct']:
                # æƒ…å¢ƒ 1: æ­·å²æ•¸æ“šæ˜¯ã€Œçµ•å°æ•¸å€¼ã€(Absolute Value)
                if base_year in history_map:
                    base_val = history_map[base_year]['Value']
                    curr_val = latest_record['Value']
                    
                    if base_val != 0:
                        # å…¬å¼: (åŸºæº– - ç¾åœ¨) / åŸºæº–
                        actual_reduction = (base_val - curr_val) / base_val
                        calc_method = f"çµ•å°å€¼è¨ˆç®— (åŸºæº–{base_year}: {base_val:,.0f} -> {Y_current}: {curr_val:,.0f})"
                    else:
                        results.append({"Focus_Area": focus_area, "Metric": metric, "Report_Year": report_year, "Risk_Level": "æ•¸æ“šéŒ¯èª¤", "Analysis_Note": "åŸºæº–å¹´æ’æ”¾é‡ç‚º 0", "Has_Negative_Warning": False, "Target_Change_Note": change_note})
                        continue
                else:
                    results.append({
                        "Focus_Area": focus_area, "Metric": metric, "Report_Year": report_year,
                        "Risk_Level": "æ•¸æ“šä¸è¶³", "Target": f"{target_year}å¹´ {target_val_str}",
                        "Analysis_Note": f"æ­·å²æ•¸æ“šç‚ºçµ•å°å€¼ï¼Œä½†åœ¨ History ä¸­æ‰¾ä¸åˆ°åŸºæº–å¹´ ({base_year}) çš„æ•¸æ“šã€‚",
                        "Has_Negative_Warning": False,
                        "Target_Change_Note": change_note
                    })
                    continue
            else:
                # æƒ…å¢ƒ 2: æ­·å²æ•¸æ“šæœ¬èº«å°±æ˜¯ã€Œæ¸›é‡ç™¾åˆ†æ¯”ã€
                actual_reduction = latest_record['Value']
                calc_method = "ç›´æ¥è®€å–ç™¾åˆ†æ¯”"

            # --- D. æ ¸å¿ƒæ¼”ç®—æ³• (Risk Logic) ---
            total_years = target_year - base_year
            elapsed_years = Y_current - base_year

            if total_years <= 0:
                results.append({"Focus_Area": focus_area, "Metric": metric, "Report_Year": report_year, "Risk_Level": "è¨­å®šéŒ¯èª¤", "Analysis_Note": "ç›®æ¨™å¹´æ—©æ–¼åŸºæº–å¹´", "Has_Negative_Warning": False, "Target_Change_Note": change_note})
                continue
            
            elapsed_years = max(0, elapsed_years)

            # æ–¹æ³•ä¸€ï¼šç·šæ€§é æœŸé€²åº¦æ³•
            expected_progress = (elapsed_years / total_years) * target_reduction
            
            if expected_progress > 0:
                gap = (expected_progress - actual_reduction) / expected_progress
            else:
                gap = 0
            
            flag1 = gap > 0.1 # è½å¾Œ 10% ä»¥ä¸Š
            flag3 = gap > 1.0 # è½å¾Œ 100% ä»¥ä¸Š

            # æ–¹æ³•äºŒï¼šè·é›¢ç›®æ¨™æ³•
            time_ratio = elapsed_years / total_years
            target_ratio = actual_reduction / target_reduction if target_reduction > 0 else 0
            
            flag2 = (time_ratio >= 0.5 and target_ratio < 0.5)

            # --- E. é¢¨éšªåˆ¤å®š ---
            if (flag1 and flag2) or flag3:
                risk_level = "ğŸ”´ é«˜åº¦é¢¨éšª"
            elif flag1 or flag2:
                risk_level = "ğŸŸ  ä¸­åº¦é¢¨éšª"
            else:
                risk_level = "ğŸŸ¢ ä½é¢¨éšª"

            # --- F. ç”¢ç”Ÿå‚™è¨» ---
            if risk_level.startswith("ğŸŸ¢"):
                note = f"é€²åº¦ç¬¦åˆé æœŸã€‚{calc_method}"
            else:
                note = (
                    f"æ‡‰æ¸› {expected_progress:.1%}, å¯¦æ¸› {actual_reduction:.1%} (Gap: {gap:.1%})ã€‚ "
                    f"{calc_method}"
                )


            result_item = {
                "Focus_Area": focus_area,
                "Report_Year": report_year,
                "Metric": metric,
                "Scope": scope,
                "Target": f"{target_year}å¹´ {target_val_str}",
                "Current_Status": f"{Y_current}å¹´ (æ¸›é‡ {actual_reduction:.1%})",
                "Risk_Level": risk_level,
                "Analysis_Note": note,
                "Has_Negative_Warning": has_negative_warning and actual_reduction < 0,
                "Target_Change_Note": change_note
            }
            results.append(result_item)
            
            # å¦‚æœæœ‰è² æ•¸è­¦å‘Šï¼Œæ·»åŠ åˆ°è­¦å‘Šåˆ—è¡¨
            if result_item["Has_Negative_Warning"]:
                warnings.append({
                    "Focus_Area": focus_area,
                    "Metric": metric,
                    "Year": Y_current,
                    "Status": actual_reduction
                })

        except Exception as e:
            results.append({
                "Focus_Area": item.get('Standardized_Focus_Area'),
                "Metric": item.get('Standardized_Metric'),
                "Report_Year": item.get('Report_Year'),
                "Risk_Level": "è¨ˆç®—éŒ¯èª¤",
                "Note": str(e),
                "Current_Status": "N/A",
                "Target": "N/A",
                "Analysis_Note": "N/A",
                "Scope": "N/A",
                "Has_Negative_Warning": False
            })

    return pd.DataFrame(results), warnings

def get_audit_prompt(current_year, content):
    # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨ {{ }} ä¾†è½‰ç¾© JSON çš„å¤§æ‹¬è™Ÿï¼Œä»¥ä¾¿ f-string æ­£ç¢ºé‹ä½œ
    template = f"""
# Role
ä½ æ˜¯ä¸€ä½ç²¾é€š ESG å ±å‘Šæ¨™æº– (å¦‚ GRI, SASB) çš„ç¨½æ ¸å“¡ã€‚ä½ çš„ä»»å‹™æ˜¯å¾ä¼æ¥­æ°¸çºŒå ±å‘Šæ›¸ä¸­æå–ã€Œæ‰¿è«¾ç›®æ¨™ã€ï¼Œä¸¦ä¾æ“šå…§å»ºçš„æ¨™æº–åŒ–å­—å…¸é€²è¡Œåˆ†é¡ï¼Œä»¥ä¾¿é€²è¡Œè·¨å¹´åº¦æ•¸æ“šæ¯”å°ã€‚

# Context
**ç›®å‰æ­£åœ¨è™•ç†çš„å ±å‘Šå¹´ä»½**: {current_year}

# Input Data
ä½ å°‡è§£ææä¾›çš„è¡¨æ ¼åœ–ç‰‡æˆ–æ–‡å­—ã€‚é€™äº›æ•¸æ“šä¾†è‡ªä¸Šè¿°å¹´ä»½çš„æ°¸çºŒå ±å‘Šæ›¸ã€‚

# Task 1: Extraction & Standardization (æå–èˆ‡æ¨™æº–åŒ–)
è«‹å°‡æå–å‡ºçš„ç›®æ¨™æ˜ å°„åˆ°ä»¥ä¸‹çš„æ¨™æº–åŒ–éšå±¤çµæ§‹ã€‚å¦‚æœä¸å®Œå…¨åŒ¹é…ï¼Œè«‹é¸æ“‡èªæ„æœ€æ¥è¿‘çš„é¸é …ã€‚

## ğŸ“š Standardized ESG Dictionary (æ¨™æº–åŒ–å­—å…¸)

### 1. ğŸŒ Focus Area: Climate (æ°£å€™è®Šé·)
   - **Target Metrics**: 
     - `Absolute GHG Reduction` (æº«å®¤æ°£é«”çµ•å°æ¸›é‡)
     - `Net Zero` (æ·¨é›¶æ’æ”¾)
     - `Renewable Energy` (å†ç”Ÿèƒ½æºæ¯”ä¾‹)
     - `Energy Efficiency` (èƒ½æºä½¿ç”¨æ•ˆç‡)
   - **Typical Scopes**: `Scope 1+2`, `Scope 3`, `Value Chain`, `Global Operations`
   - **Strict Formatting Rule**: 
     - ç•¶ç›®æ¨™æ¶‰åŠ Scope 1 èˆ‡ Scope 2 æ™‚ï¼ŒOutput Scope æ¬„ä½è«‹**åš´æ ¼**å¡«å…¥ `Scope 1+2`ã€‚
     - **ç¦æ­¢**åœ¨ Scope æ¬„ä½åŠ å…¥åœ°å€ã€å­å…¬å¸æˆ–æ‹¬è™Ÿè¨»è¨˜ (ä¾‹å¦‚ï¼š**ä¸è¦å¯«** `Scope 1+2 (Taiwan Operations)` æˆ– `Scope 1+2 (Company only)`ï¼Œä¸€å¾‹åˆªé™¤æ‹¬è™Ÿå…§å®¹ï¼Œåªä¿ç•™ `Scope 1+2`)ã€‚

### 2. ğŸ“¦ Focus Area: Packaging (åŒ…è£èˆ‡å¾ªç’°ç¶“æ¿Ÿ)
   - **Target Metrics**: 
     - `Recycled Content` (å†ç”Ÿæ–™ä½¿ç”¨æ¯”ä¾‹, e.g., rPET)
     - `Virgin Plastic Reduction` (åŸç”Ÿå¡‘è† æ¸›é‡)
     - `Packaging Design` (å¯å›æ”¶/å¯å †è‚¥è¨­è¨ˆ, e.g., Recyclability)
     - `Reuse Models` (é‡è¤‡ä½¿ç”¨æ¨¡å¼/æ¸›é‡)
     - `Waste to Landfill` (å»¢æ£„ç‰©æ©åŸ‹ç‡)
   - **Typical Scopes**: `Plastic Packaging`, `Beverage Containers`, `Food Packaging`, `Global Portfolio`

### 3. ğŸ’§ Focus Area: Water (æ°´è³‡æº)
   - **Target Metrics**: 
     - `Water Replenishment` (æ°´è³‡æºå›è£œ)
     - `Water Use Efficiency` (ç”¨æ°´æ•ˆç‡/å¼·åº¦)
   - **Typical Scopes**: `High Water-Risk Areas`, `Manufacturing Operations`

### 4. ğŸŒ± Focus Area: Agriculture (æ°¸çºŒè¾²æ¥­)
   - **Target Metrics**: 
     - `Regenerative Agriculture` (å†ç”Ÿè¾²æ¥­æ¡ç”¨é¢ç©)
     - `Sustainably Sourced` (æ°¸çºŒæ¡è³¼æ¯”ä¾‹)
   - **Typical Scopes**: `Key Ingredients`, `Direct Supply Chain`

### 5. ğŸ‘¥ Focus Area: Human Rights & Social (äººæ¬Šèˆ‡ç¤¾æœƒ)
   - **Target Metrics**: 
     - `Gender Diversity` (æ€§åˆ¥å¤šæ¨£æ€§/ç®¡ç†å±¤æ¯”ä¾‹)
     - `Safety` (å·¥å‚·ç‡/å®‰å…¨äº‹æ•…)
     - `Human Rights Audit` (äººæ¬Šç›¡è·èª¿æŸ¥)
   - **Typical Scopes**: `Global Workforce`, `Management Roles`, `Tier 1 Suppliers`

# Task 2: Data Cleaning Rules (è³‡æ–™æ¸…æ´—è¦å‰‡)
1. **å¿½ç•¥æ­·å²æ•¸æ“š**: è«‹å¿½ç•¥æ‰€æœ‰å°æ–¼æˆ–ç­‰æ–¼ {current_year} çš„é€²åº¦æ•¸å€¼ (Results/Status)ï¼Œæˆ‘å€‘åªé—œå¿ƒã€Œæœªä¾†çš„ç›®æ¨™ (Target)ã€ã€‚
2. **Deadline Logic**:
   - å„ªå…ˆæª¢æŸ¥ç›®æ¨™æè¿°å…§çš„å¹´ä»½ (å¦‚ "by 2025")ã€‚
   - è‹¥ç„¡ï¼Œå‰‡ä½¿ç”¨è¡¨é ­å¹´ä»½ (å¦‚ "2030 Target")ã€‚
3. **Value Parsing**: åªæå–ç›®æ¨™æ•¸å€¼ (å¦‚ "100%", "50%")ï¼Œå»é™¤æ–‡å­—æ•˜è¿°ã€‚

# Output JSON Schema
è«‹è¼¸å‡ºä¸€å€‹ JSON Listï¼š
[
  {{
    "Report_Year": {current_year},
    "Standardized_Focus_Area": "String (e.g., 'Packaging', 'Climate')",
    "Standardized_Metric": "String (e.g., 'Recycled Content')",
    "// Level 3: é©ç”¨ç¯„ç–‡/æè³ª
    // æ³¨æ„ï¼šå°æ–¼ Climate é ˜åŸŸï¼Œè«‹å¿½ç•¥ "(Taiwan Operations)" ç­‰åœ°å€å¾Œç¶´ï¼Œåªè¼¸å‡ºæ¨™æº–ç¯„ç–‡ (å¦‚ "Scope 1+2")
    "Scope": "String (e.g., 'Plastic Packaging', 'Scope 1+2', 'Scope 3')",
    "Original_Goal_Text": "String (ä¿ç•™å ±å‘Šä¸­çš„å®Œæ•´åŸå§‹æè¿°)",
    "Target_Deadline": Number (e.g., 2025, 2030),
    "Target_Value": "String (e.g., '25%', '50%', 'Net Zero')",
    "Baseline_Year": "String (è‹¥æœ‰æåŠåŸºæº–å¹´å‰‡å¡«å…¥ï¼Œå¦å‰‡ null)",
    "Progress_History": [
       {{ "Year": Number, "Value": "String" }}
    ]
  }}
]

# Begin Extraction
è«‹åˆ†æä»¥ä¸‹å…§å®¹ï¼š
{content}
"""
    return template

# ==========================================
# 3. Streamlit ç¶²é ä»‹é¢ (Web Interface)
# ==========================================

st.title("ğŸŒ± ESG å ±å‘Šæ›¸æ¼‚ç¶ ç¨½æ ¸å°å¹«æ‰‹")
st.markdown("""
æœ¬å·¥å…·æä¾›å¾ **PDF å ±å‘Šè½‰æ›** åˆ° **ç¸¾æ•ˆé¢¨éšªç¨½æ ¸** çš„ä¸€ç«™å¼æµç¨‹ã€‚
è«‹ä¾åºä½¿ç”¨ä¸‹æ–¹åˆ†é åŠŸèƒ½ï¼š
""")

# å»ºç«‹ä¸‰å€‹ä¸»è¦é ç±¤
tab1, tab2, tab3 = st.tabs([
    "ğŸ“„ 1. å ±å‘Šè½‰æ› (PDF to MD)", 
    "ğŸ¤– 2. ç”¢ç”Ÿç¨½æ ¸ Prompt", 
    "ğŸ“Š 3. ç¸¾æ•ˆè¿½è¹¤èˆ‡é¢¨éšªè©•ä¼°"
])

# ------------------------------------------
# Tab 1: å ±å‘Šè½‰æ› (PDF -> Markdown)
# ------------------------------------------
with tab1:
    st.header("æ­¥é©Ÿä¸€ï¼šä¸Šå‚³ä¸¦è½‰æ›å ±å‘Šæ›¸")
    st.markdown("å°‡ PDF æ ¼å¼çš„ ESG å ±å‘Šæ›¸è½‰æ›ç‚º AI å¯è®€çš„ Markdown æ ¼å¼ã€‚")
    
    uploaded_pdf = st.file_uploader("ä¸Šå‚³ ESG å ±å‘Šæ›¸ (PDF)", type=["pdf"], key="pdf_uploader")
    
    # ç‹€æ…‹ä¿å­˜ï¼šMarkdown å…§å®¹
    if 'markdown_content' not in st.session_state:
        st.session_state.markdown_content = ""
    
    # å˜—è©¦å¾æª”åè‡ªå‹•æå–å¹´ä»½
    default_year = 2024
    if uploaded_pdf:
        match = re.search(r'20\d{2}', uploaded_pdf.name)
        if match:
            default_year = int(match.group(0))
            
    report_year = st.number_input("è¨­å®šå ±å‘Šå¹´ä»½", min_value=2000, max_value=2030, value=default_year, key="report_year_input")
    st.session_state.report_year = report_year

    if uploaded_pdf is not None:
        if st.button("é–‹å§‹è½‰æ›"):
            st.info(f"æ­£åœ¨è™•ç†æª”æ¡ˆ: {uploaded_pdf.name} ...")
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_pdf:
                tmp_pdf.write(uploaded_pdf.read())
                tmp_pdf_path = tmp_pdf.name

            try:
                md = MarkItDown()
                result = md.convert(tmp_pdf_path)
                st.session_state.markdown_content = result.text_content
                os.remove(tmp_pdf_path)
                st.success("è½‰æ›æˆåŠŸï¼è«‹è‡³ã€Œç”¢ç”Ÿç¨½æ ¸ Promptã€åˆ†é æŸ¥çœ‹ã€‚")
                
            except Exception as e:
                st.error(f"è½‰æ›éŒ¯èª¤: {e}")
                if os.path.exists(tmp_pdf_path): os.remove(tmp_pdf_path)
    
    if st.session_state.markdown_content:
        with st.expander("æŸ¥çœ‹è½‰æ›å¾Œçš„ Markdown å…§å®¹"):
            st.text_area("å…§å®¹é è¦½", st.session_state.markdown_content, height=300)
            st.download_button(
                label="ä¸‹è¼‰ Markdown (.md)",
                data=st.session_state.markdown_content,
                file_name=f"report_{report_year}.md",
                mime="text/markdown"
            )

# ------------------------------------------
# Tab 2: ç”¢ç”Ÿç¨½æ ¸ Prompt
# ------------------------------------------
with tab2:
    st.header("æ­¥é©ŸäºŒï¼šç”Ÿæˆ AI ç¨½æ ¸ Prompt")
    st.markdown("å°‡è½‰æ›å¾Œçš„å…§å®¹çµåˆæ¨™æº–åŒ–æŒ‡ä»¤ï¼Œç”¢ç”Ÿå¯ä¾› ChatGPT/Claude/Gemini ä½¿ç”¨çš„ Promptã€‚")
    
    if st.session_state.markdown_content:
        final_prompt = get_audit_prompt(st.session_state.report_year, st.session_state.markdown_content)
        
        st.info("ğŸ’¡ è«‹è¤‡è£½ä¸‹æ–¹å…§å®¹ï¼Œè²¼çµ¦ LLM æ¨¡å‹ï¼Œä¸¦å°‡å…¶å›å‚³çš„ JSON å­˜æª”ä¾›æ­¥é©Ÿä¸‰ä½¿ç”¨ã€‚")
        st.text_area("Prompt é è¦½", final_prompt, height=400)
        
        st.download_button(
            label="ä¸‹è¼‰å®Œæ•´ Prompt (.txt)",
            data=final_prompt,
            file_name=f"Audit_Prompt_{st.session_state.report_year}.txt",
            mime="text/plain"
        )
    else:
        st.warning("è«‹å…ˆåœ¨æ­¥é©Ÿä¸€ä¸Šå‚³ä¸¦è½‰æ› PDF å ±å‘Šã€‚")

# ------------------------------------------
# Tab 3: ç¸¾æ•ˆè¿½è¹¤èˆ‡é¢¨éšªè©•ä¼° (æ ¸å¿ƒé‚è¼¯å€)
# ------------------------------------------
with tab3:
    st.header("æ­¥é©Ÿä¸‰ï¼šç¸¾æ•ˆè¿½è¹¤èˆ‡é¢¨éšªè©•ä¼°")
    st.markdown("""
    è«‹ä¸Šå‚³ç”± LLM ç”¢å‡ºçš„ **çµæ§‹åŒ– JSON æª”æ¡ˆ**ã€‚
    ç³»çµ±å°‡è‡ªå‹•åŸ·è¡Œï¼š
    1. **è§£ææ­·å¹´æ•¸æ“š** (æ”¯æ´çµ•å°å€¼è½‰ç™¾åˆ†æ¯”ï¼Œè‡ªå‹•å°‡ `(5)%` è½‰ç‚º `-5%`)ã€‚
    2. **å°æ‡‰åŸºæº–å¹´** (Baseline Mapping)ã€‚
    3. **è¨ˆç®—é¢¨éšªç­‰ç´š** (ç·šæ€§é æœŸæ³• + è·é›¢ç›®æ¨™æ³•)ã€‚
    """)
    
    uploaded_json = st.file_uploader("ä¸Šå‚³ LLM ç”¢å‡ºçš„ JSON æª”æ¡ˆ", type=["json"], key="json_uploader")

    if uploaded_json is not None:
        try:
            # è®€å– JSON
            json_data = json.load(uploaded_json)
            st.success(f"æˆåŠŸè®€å–æª”æ¡ˆï¼å…± {len(json_data)} ç­†ç›®æ¨™è³‡æ–™ã€‚")
            
            # åŸ·è¡Œè¨ˆç®—
            with st.spinner('æ­£åœ¨é€²è¡Œé¢¨éšªè©•ä¼°æ¼”ç®—æ³•...'):
                df_result, warnings_list = calculate_risk(json_data)
            
            # é¡¯ç¤ºè­¦å‘Šå½ˆçª— (Current_Status èƒŒé“è€Œé¦³)
            if warnings_list:
                for warn in warnings_list:
                    st.error(
                        f"âŒå¹´åº¦: {warn['Year']} - {warn['Focus_Area']} - {warn['Metric']}\n\n"
                        f"è©²å¹´åº¦çš„æ¸›é‡ç‹€æ³ç‚ºè² æ•¸ ({warn['Status']:.1%})ï¼Œ"
                        f"èˆ‡ç›®æ¨™èƒŒé“è€Œé¦³ï¼"
                    )

            # é¡¯ç¤ºçµæœ
            st.subheader("ğŸ“Š ç¨½æ ¸åˆ†æçµæœ")

            # ç›´æ¥é¡¯ç¤ºè¡¨æ ¼ï¼ˆéš±è—å…§éƒ¨æ¬„ä½ Has_Negative_Warningï¼‰
            df_display = df_result.drop(columns=['Has_Negative_Warning'], errors='ignore')
            # ä¾ Report_Year é è¨­å‡åºæ’åºï¼ˆè‹¥æœ‰æ­¤æ¬„ä½ï¼‰
            if 'Report_Year' in df_display.columns:
                try:
                    df_display = df_display.sort_values(by='Report_Year', ascending=True)
                except Exception:
                    pass
            st.dataframe(df_display, use_container_width=True)

            # ä¸‹è¼‰ CSV
            # åœ¨å°å‡ºå‰ç§»é™¤ Has_Negative_Warning åˆ—
            df_export = df_result.drop(columns=['Has_Negative_Warning'], errors='ignore')
            csv = df_export.to_csv(index=False, encoding='utf-8-sig')
            base_name = uploaded_json.name.replace(".json", "")
            file_name = f"Audit_Result_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{base_name}.csv"
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´åˆ†æå ±è¡¨ (CSV)",
                data=csv,
                file_name=file_name,
                mime="text/csv",
            )

        except Exception as e:
            st.error(f"åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            st.info("è«‹ç¢ºèªä¸Šå‚³çš„ JSON æ ¼å¼æ˜¯å¦ç¬¦åˆ Prompt å®šç¾©çš„ Schemaã€‚")
    else:
        st.info("ğŸ‘‹ ç­‰å¾…ä¸Šå‚³ JSON æª”æ¡ˆä¸­...")